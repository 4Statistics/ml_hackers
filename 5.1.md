CHAPTER 5
Regression: Predicting Page Views

Introducing Regression
In the abstract, regression is a very simple concept: you want to predict one set of
numbers given another set of numbers. For example, actuaries might want to predict
how long a person will live given their smoking habits, while meteorologists might want
to predict the next day’s temperature given the previous day’s temperature. In general,
we’ll call the numbers you’re given inputs and the numbers you want to predict out-puts. You’ll also sometimes hear people refer to the inputs as predictors or features.
What makes regression different from classification is that the outputs are really num-bers. In classification problems like those we described in [Chapter 3][1], you might use
numbers as a dummy code for a categorical distinction so that 0 represents ham and 1
represents spam. But these numbers are just symbols; we’re not exploiting the “num-berness” of 0 or 1 when we use dummy variables. In regression, the essential fact about
the outputs is that they really are numbers: you want to predict things like temperatures,
which could be 50 degrees or 71 degrees. Because you’re predicting numbers, you want
to be able to make strong statements about the relationship between the inputs and the
outputs: you might want to say, for example, that when the number of packs of ciga-rettes a person smokes per day doubles, their predicted life span gets cut in half.
The problem, of course, is that wanting to make precise numerical predictions isn’t the
same thing as actually being able to make predictions. To make quantitative predic-tions, we need to come up with some rule that can leverage the information we have
access to. The various regression algorithms that statisticians have developed over the
last 200 years all provide different ways to make predictions by turning inputs into
outputs. In this chapter, we’ll cover the workhorse regression model, which is called
linear regression.


[1]: ./3.1.md  "Chapter 3"