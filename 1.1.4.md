## 1.1.4 机器学习的R基础 ##

正如我们在开头说的，我们坚信学习新技能的最好方式就是带着自己想要解决的问题或想要回答的疑问开始。从更高的层次来看自己的工作，会让你的案例学习更加有效率。在这个R基本概念的复习过程中，我们不会从一个具体的机器学习问题入手，但是我们会在用R进行数据工作的时候遇到一些数据处理相关的问题。我们会在后面的案例中看到，为了让数据适应我们的分析格式，我们常常会在输出的格式处理上花费大量的时间，而进行分析编码的时间则比较少。

下面这个例子是一个很有娱乐价值的问题。最近，数据服务商 Infochimps.com 发布了一份包含60,000个UFO目击报告的文档，这份数据来源于世界各地上百年的报告。虽然这是一份国际化的数据集，但是主要的目击数据还是来源于美国。根据这份数据的时间和各种细节记录，我们可能会提出以下的问题：UFO目击是否有季节性的趋势？美国不同地区所发现的UFO目击现象有何不同？

这是一个很不错的用来进行数据探索的数据集，因为它内容很丰富，结构清晰，并且很有趣。同时由于他是由大文本构成的，这将对本书后面的案例分析很有帮助，因为我们的案例分析的数据都是大文本。对于这样的文本文件，常常会有不少麻烦的部分要处理，我们会使用基本的R函数和一些扩展库来清理和组织数据。本节我们会带着你一步一步，尝试一个完整的分析用来回答我们上面提到的几个问题。你可以从本章文件夹下的 ufo_sightings.R 中获得源码。我们会从加载数据和扩展包开始分析。

### 加载函数库及数据 ###
首先, 我们会加载 ggplot2 包, 我们将会在最后进行可视化分析的时候使用它：

    library(ggplot2)

当加载 ggplot2 的时候，你会注意到这个包同时加载了另外两个依赖包：plyr 和 reshape包。这两个包都是用来操作和组织数据的，在本例中我们将会使用plyr来收集和组织数据。

下一步是从ufo_awesome.tsv文件(在第一章的data/ufo/目录下，可以在README中找到链接)中把数据加载到R环境。需要注意的是，这个文件使用了制表符来区分数据，也就是说我们需要用 read.delim 函数来读取数据。由于R严格遵自己的守默认规则，我们要格外小心谨慎的注意自己所使用函数的默认参数。假如我们没用用过 read.delim 函数，需要看一下帮助手册，或者说我们完全不知道有这么个函数来处理制表符，我们要怎么做呢？R提供了一组有用的函数来帮助我们：

    ?read.delim                 # 打开一个函数的帮助文件
    ??base::delim               # 在base包中的所有帮助文件中搜索delim
    help.search("delimited")    # 在所有帮助文件中搜索delimited
    RSiteSearch("parsing text") # 在R官方站点中搜索parsing text

第一个例子中，我们在函数的开头添加了一个问号，它将会打开指定函数的帮助文件，这是R中的一个很有用的快捷操作。我们同样可以使用??和::组合在包内搜索指定的关键词。双问号表示搜索一个指定单词。在这个例子中我们用双冒号在base包中搜索delim词。R同样支持简短的helo.search和RSiteSearch来进行基本搜索。help.search会搜索所有已安装包的帮助文件，RsiteSearch会搜索R官方站点和邮件列表。由于本书的R指南比较精简，我们强烈建议你自己通过这些搜索功能来浏览具体的R函数。

对于UFO的数据来说，我们需要为read.delim函数手动提供一些参数以便于读取数据。首先，我们需要告诉函数我们的数据是如何分割的。我们知道这是一个用制表符分割的文件，所以我们把delim的seq参数设置为制表符（\t）。然后，当delim函数读取数据时，R会尝试把每一列的数据转换成R自己可用的合适类型。在我们的例子中，所有的列都是字符串，但是read.*的所有函数默认都是把字符串转换为factor类型，factor类型是一种分类变量（categorical variable），这不是我们所期望的。因此我们要把stringsAsFactors设置为FALSE来防止转换。事实上，关闭这项默认特性是很好的习惯，尤其是当你在处理不熟悉的数据时。另外，这组数据的第一行没有表头(列名)，因此我们需要把header属性同样设置为FALSE。最后，数据中有很多空元素，我们希望这些被R标记为NA的值以空字符串的形式出现，我们可以现实的定义na.string为空即可：

    ufo<-read.delim("data/ufo/ufo_awesome.tsv", sep="\t", stringsAsFactors=FALSE,header=FALSE, na.strings="")

>>分类变量（categorical variable）是一种用来表示观测对象在所属分类的类型。在统计学中，分类变量非常重要，这是因为我们可能会对某个观察对象为何属于某种类型感兴趣。在R中，我们使用factor类型来表示分类变量，这在本质上其实是使用数字索引来表示不同的字符串标签。在本例中，我们会把某种字符串--比如州的简写--使用as.factor转换成分类变量，这会给每一个州简写指定一个唯一的数字编号。我们将会在后面多次重复进行这个过程。

We now have a data frame containing all of the UFO data! Whenever you are working with data frames, especially when they are from external data sources, it is always a good idea to inspect the data by hand. Two great functions for doing this are head and tail. These functions will print the first and last six entries in a data frame:

    head(ufo)
    V1            V2            V3         V4        5              V6
    1 19951009 19951009     Iowa City, IA <NA>      <NA> Man repts. witnessing "flash..
    ...
    
The first obvious issue with the data frame is that the column names are generic. Using the documentation for this data set as a reference, we can assign more meaningful labels to the columns. Having meaningful column names for data frames is an important best practice. It makes your code and output easier to understand, both for you and other audiences. We will use the names function, which can either access the column labels for a data structure or assign them. From the data documentation, we construct a character vector that corresponds to the appropriate column names and pass it to the names functions with the data frame as its only argument:

    names(ufo)<-c("DateOccurred","DateReported","Location","ShortDescription", "Duration","LongDescription")

From the head output and the documentation used to create column headings, we know that the first two columns of data are dates. As in other languages, R treats dates as a special type, and we will want to convert the date strings to actual date types. To do this, we will use the as.Date function, which will take the date string and attempt to convert it to a Date object. With this data, the strings have an uncommon date format of the form YYYMMDD. As such, we will also have to specify a format string in as.Date so the function knows how to convert the strings. We begin by converting the DateOccurred column:

    ufo$DateOccurred<-as.Date(ufo$DateOccurred, format="%Y%m%d")
    Error in strptime(x, format, tz = "GMT") : input string is too long

We’ve just come upon our first error! Though a bit cryptic, the error message contains the substring “input string too long”, which indicates that some of the entries in the DateOccurred column are too long to match the format string we provided. Why might this be the case? We are dealing with a large text file, so perhaps some of the data was malformed in the original set. Assuming this is the case, those data points will not be parsed correctly when loaded by read.delim, and that would cause this sort of error. Because we are dealing with real-world data, we’ll need to do some cleaning by hand.

### Converting date strings and dealing with malformed data ###
To address this problem, we first need to locate the rows with defective date strings, then decide what to do with them. We are fortunate in this case because we know from the error that the errant entries are “too long.” Properly parsed strings will always be eight characters long, i.e., “YYYYMMDD”. To find the problem rows, therefore, we simply need to find those that have strings with more than eight characters. As a best practice, we first inspect the data to see what the malformed data looks like, in order to get a better understanding of what has gone wrong. In this case, we will use the head function as before to examine the data returned by our logical statement.

Later, to remove these errant rows, we will use the ifelse function to construct a vector of TRUE and FALSE values to identify the entries that are eight characters long (TRUE) and those that are not (FALSE). This function is a vectorized version of the typical if-else logical switch for some Boolean test. We will see many examples of vectorized opera- tions in R. They are the preferred mechanism for iterating over data because they are often—but not always—more efficient than explicitly iterating over a vector:1

    head(ufo[which(nchar(ufo$DateOccurred)!=8 | nchar(ufo$DateReported)!=8),1])
    [1] "ler@gnv.ifas.ufl.edu"
    [2] "0000"
    [3] "Callers report sighting a number of soft white balls of lights headingin an easterly directing then changing direction to the west beforespeeding off to the north west."
    [4] "0000"
    [5] "0000"
    [6] "0000"
    good.rows<-ifelse(nchar(ufo$DateOccurred)>!=8 | nchar(ufo$DateReported)!=8,FALSE, TRUE)
    length(which(!good.rows))
    [1] 371 
    ufo<-ufo[good.rows,]

We use several useful R functions to perform this search. We need to know the length of the string in each entry of DateOccurred and DateReported, so we use the nchar function to compute this. If that length is not equal to eight, then we return FALSE. Once we have the vectors of Booleans, we want to see how many entries in the data frame have been malformed. To do this, we use the which command to return a vector of vector indices that are FALSE. Next, we compute the length of that vector to find the number of bad entries. With only 371 rows not conforming, the best option is to simply remove these entries and ignore them. At first, we might worry that losing 371 rows of data is a bad idea, but there are over 60,000 total rows, and so we will simply ignore those malformed rows and continue with the conversion to Date types:

    ufo$DateOccurred<-as.Date(ufo$DateOccurred, format="%Y%m%d") 
    ufo$DateReported<-as.Date(ufo$DateReported, format="%Y%m%d")

Next, we will need to clean and organize the location data. Recall from the previous head call that the entries for UFO sightings in the United States take the form “City, State”. We can use R’s regular expression integration to split these strings into separate columns and identify those entries that do not conform. The latter portion, identifying those that do not conform, is particularly important because we are only interested in sighting variation in the United States and will use this information to isolate those entries.

### Organizing location data ###
To manipulate the data in this way, we will first construct a function that takes a string as input and performs the data cleaning. Then we will run this function over the location data using one of the vectorized apply functions:

    get.location<-function(l) {
    split.location<-tryCatch(strsplit(l,",")[[1]], error= function(e) return(c(NA, NA))) clean.location<-gsub("^ ","",split.location)
    if (length(clean.location)>2) {
    return(c(NA,NA)) }
    else { return(clean.location)
    } }

There are several subtle things happening in this function. First, notice that we are wrapping the strsplit command in R’s error-handling function, tryCatch. Again, not all of the entries are of the proper “City, State” form, and in fact, some do not even contain a comma. The strsplit function will throw an error if the split character is not matched; therefore, we have to catch this error. In our case, when there is no comma to split, we will return a vector of NA to indicate that this entry is not valid. Next, the original data included leading whitespace, so we will use the gsub function (part of R’s suite of functions for working with regular expressions) to remove the leading white- space from each character. Finally, we add an additional check to ensure that only those location vectors of length two are returned. Many non-US entries have multiple com- mas, creating larger vectors from the strsplit function. In this case, we will again return an NA vector.

With the function defined, we will use the lapply function, short for “list-apply,” to iterate this function over all strings in the Location column. As mentioned, members of the apply family of functions in R are extremely useful. They are constructed of the form apply(vector, function) and return results of the vectorized application of the function to the vector in a specific form. In our case, we are using lapply, which always returns a list:

    city.state<-lapply(ufo$Location, get.location) head(city.state)
    [[1]]
    [1] "Iowa City" "IA"
    [[2]]
    [1] "Milwaukee" "WI"
    [[3]]
    [1] "Shelton" "WA"
    [[4]]
    [1] "Columbia" "MO"
    [[5]]
    [1] "Seattle" "WA"
    [[6]]
    [1] "Brunswick County" "ND"

As you can see in this example, a list in R is a key-value-style data structure, wherein the keys are indexed by the double bracket and values are contained in the single bracket. In our case the keys are simply integers, but lists can also have strings as keys.2 Though convenient, having the data stored in a list is not desirable, because we would like to add the city and state information to the data frame as separate col- umns. To do this, we will need to convert this long list into a two-column matrix, with the city data as the leading column:

    location.matrix<-do.call(rbind, city.state)
    ufo<-transform(ufo, USCity=location.matrix[,1], USState=tolower(location.matrix[,2]),
    stringsAsFactors=FALSE)

To construct a matrix from the list, we use the do.call function. Similar to the apply functions, do.call executes a function call over a list. We will often use the com- bination of lapply and do.call to manipulate data. In the preceding example we pass the rbind function, which will “row-bind” all of the vectors in the city.state list to create a matrix. To get this into the data frame, we use the transform function. We create two new columns: USCity and USState from the first and second columns of location.matrix, respectively. Finally, the state abbreviations are inconsistent, with some uppercase and others lowercase, so we use the tolower function to make them all lowercase.

### Dealing with data outside our scope ###

### Aggregating and organizing the data ###

### Analyzing the data ###

## 链接 ##
* [目录](<list.md>)
* [上一节 加载和安装R包](1.1.3.md)
* [下一节 R延伸阅读](1.1.5.md)