第三章 分类：垃圾邮件过滤
===============================

## 3.1 这一类还是那一类: 二元分类 ##
At the very end of Chapter 2, we quickly presented an example of classification. We used heights and weights to predict whether a person was a man or a woman. With our example graph, we were able to draw a line that split the data into two groups: one group where we would predict “male” and another group where we would predict “female.” This line was called a separating hyperplane, but from now on we’ll use the term “decision boundary,” because we’ll be working with data that can’t be classified properly using only straight lines. For example, imagine that your data looked like the data set shown in Example 3-1.
This plot might depict people who are at risk for a certain ailment and those who are not. Above and below the black horizontal lines we might predict that a person is at risk, but inside we would predict good health. These black lines are thus our decision boundary. Suppose that the blue dots represent healthy people and the red dots rep- resent people who suffer from a disease. If that were the case, the two black lines would work quite well as a decision boundary for classifying people as either healthy or sick.
Producing general-purpose tools that let us handle problems where the decision bound- ary isn’t a single straight line has been one of the great achievements of machine learn- ing. One approach in particular that we’ll focus on later is called the kernel trick, which has the remarkable property of allowing us to work with much more sophisticated decision boundaries at almost no additional computational cost.
But before we begin to understand how these decision boundaries are determined in practice, let’s review some of the big ideas in classification.
We’re going to assume that we have a set of labeled examples of the categories we want to learn how to identify. These examples consist of a label, which we’ll also call a class or type, and a series of measured variables that describe each example. We’ll call these measurements features or predictors. The height and weight columns we worked with earlier are examples of features that we could use to guess the “male” and “female” labels we were working with before.

Examples of classifications can be found anywhere you look for them:
• Given the results of a mammogram, does a patient have breast cancer?
• Do blood pressure measurements suggest that a patient has hypertension?
• Does a political candidate’s platform suggest that she is a Republican candidate or a Democratic candidate?
• Does a picture uploaded to a social network contain a face in it?
• Was The Tempest written by William Shakespeare or Francis Bacon?

In this chapter, we’re going to focus on problems with text classification that are closely related to the tools you could use to answer the last question in our list. In our exercise, however, we’re going to build a system for deciding whether an email is spam or ham.
Our raw data comes from the SpamAssassin public corpus, available for free download at http://spamassassin.apache.org/publiccorpus/. Portions of this corpus are included in the code/data/ folder for this chapter and will be used throughout this chapter. At the unprocessed stage, the features are simply the contents of the raw email as plain text.
This raw text provides us with our first problem. We need to transform our raw text data into a set of features that describe qualitative concepts in a quantitative way. In our case, that will be a 0/1 coding strategy: spam or ham. For example, we may want to determine the following: “Does containing HTML tags make an email more likely to be spam?” To answer this, we will need a strategy for turning the text in our email into numbers. Fortunately, the general-purpose text-mining packages available in R will do much of this work for us.
For that reason, much of this chapter will focus on building up your intuition for the types of features that people have used in the past when working with text data. Feature generation is a major topic in current machine learning research and is still very far from being automated in a general-purpose way. At present, it’s best to think of the features being used as part of a vocabulary of machine learning that you become more familiar with as you perform more machine learning tasks.

>>Just as learning the words of a new language builds up an intuition for what could realistically be a word, learning about the features people have used in the past builds up an intuition for what features could reasonably be helpful in the future.

When working with text, historically the most important type of feature that’s been used is word count. If we think that the text of HTML tags are strong indicators of whether an email is spam, then we might pick terms like “html” and “table” and count how often they occur in one type of document versus the other. To show how this approach would work with the SpamAssassin public corpus, we’ve gone ahead and counted the number of times the terms “html” and “table” occurred. Table 3-1 shows the results.

![table 3-1](https://raw.github.com/royguo/ml_hackers/master/images/table 3-1.png "table 3-1")
![figure 3-1](https://raw.github.com/royguo/ml_hackers/master/images/figure 3-1.png "figure 3-1")

For every email in our data set, we’ve also plotted the class memberships in Figure 3-1. This plot isn’t very informative, because too many of the data points in our data set overlap. This sort of problem comes up quite often when you work with data that contains only a few unique values for one or more of your variables. As this is a recurring problem, there is a standard graphical solution: we simply add random noise
to the values before we plot. This noise will “separate out” the points to reduce the amount of over-plotting.This addition of noise is called jittering, and is very easy to produce in ggplot2 (see Figure 3-2).

![figure 3-2](https://raw.github.com/royguo/ml_hackers/master/images/figure 3-2.png "figure 3-2")

This last plot suggests that we could do a so-so job of deciding whether an email is spam simply by counting the number of times the terms “html” and “table” occur.

>>The commands used to create the plots in Figures 3-1 and 3-2 begin at line 129 of the email_classify.R file in the code/ folder for this chapter.

In practice, we can do a much better job by using many more than just these two very obvious terms. In fact, for our final analysis we’ll use several thousand terms. Even though we’ll only use word-count data, we’ll still get a relatively accurate classification. In the real world, you’d want to use other features beyond word counts, such as falsified headers, IP or email black lists, etc., but here we only want to introduce the basics of text classification.

Before we can proceed, we should review some basic concepts of conditional proba- bility and discuss how they relate to classifying a message based on its text.

## 链接 ##
* [目录](<list.md>)
* [上一节](0.md)
* [下一节 3.2](3.2.md)